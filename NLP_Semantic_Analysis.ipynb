{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QDo-1gmbtCp0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Load input.xlsx\n",
        "input_data = pd.read_excel(\"Input.xlsx\")\n",
        "\n",
        "# Iterate through each URL\n",
        "for index, row in input_data.iterrows():\n",
        "    url_id = row['URL_ID']\n",
        "    url = row['URL']\n",
        "\n",
        "    # Fetch the HTML content of the page\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract article title and text\n",
        "    article_title = soup.find('title').text.strip()\n",
        "    article_text = ' '.join([p.text for p in soup.find_all('p')])\n",
        "\n",
        "    # Save the extracted article in a text file\n",
        "    with open(f\"{url_id}.txt\", 'w', encoding='utf-8') as file:\n",
        "        file.write(f\"{article_title}\\n{article_text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "904FkZ0mBznJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from textblob import TextBlob\n",
        "import syllables\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import os\n",
        "\n",
        "# Load input.xlsx\n",
        "input_data = pd.read_excel(\"Input.xlsx\")\n",
        "\n",
        "# Create lists to store output data\n",
        "output_url_ids = []\n",
        "positive_scores = []\n",
        "negative_scores = []\n",
        "polarity_scores = []\n",
        "subjectivity_scores = []\n",
        "avg_sentence_lengths = []\n",
        "percentage_complex_words_list = []\n",
        "fog_indices = []\n",
        "avg_words_per_sentence_list = []\n",
        "complex_word_counts = []\n",
        "word_counts = []\n",
        "syllables_per_words = []\n",
        "personal_pronouns_list = []\n",
        "avg_word_lengths = []\n",
        "\n",
        "folder_path = \"/content\"\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.txt'):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        try:\n",
        "            print(f\"Processing file: {file_path}\")  # Print file path for clarity\n",
        "\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                article_text = file.read()\n",
        "\n",
        "            blob = TextBlob(article_text)  # Create the TextBlob object\n",
        "\n",
        "            # Compute variables\n",
        "            positive_score = blob.sentiment.polarity\n",
        "            negative_score = -blob.sentiment.polarity\n",
        "            polarity_score = blob.sentiment.polarity\n",
        "            subjectivity_score = blob.sentiment.subjectivity\n",
        "            avg_sentence_length = len(blob.sentences) / len(blob.words)\n",
        "            percentage_complex_words = len([word for word in blob.words if syllables.estimate(word) >= 3]) / len( blob.words) * 100\n",
        "            fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
        "            avg_words_per_sentence = len(blob.words) / len(blob.sentences)\n",
        "            complex_word_count = len([word for word in blob.words if syllables.estimate(word) >= 3])\n",
        "            word_count = len(blob.words)\n",
        "            syllables_per_word = sum([syllables.estimate(word) for word in blob.words]) / len(blob.words)\n",
        "            personal_pronouns = len([word for word in blob.words if word.lower() in ['i', 'me', 'my', 'mine', 'myself']])\n",
        "            avg_word_length = sum(len(word) for word in blob.words) / len(blob.words)\n",
        "\n",
        "            # Append the results to the lists\n",
        "            output_url_ids.append(row['URL_ID'])  # Assuming URL_ID is a column in our Input.xlsx\n",
        "            positive_scores.append(positive_score)\n",
        "            negative_scores.append(negative_score)\n",
        "            polarity_scores.append(polarity_score)\n",
        "            subjectivity_scores.append(subjectivity_score)\n",
        "            avg_sentence_lengths.append(avg_sentence_length)\n",
        "            percentage_complex_words_list.append(percentage_complex_words)\n",
        "            fog_indices.append(fog_index)\n",
        "            avg_words_per_sentence_list.append(avg_words_per_sentence)\n",
        "            complex_word_counts.append(complex_word_count)\n",
        "            word_counts.append(word_count)\n",
        "            syllables_per_words.append(syllables_per_word)\n",
        "            personal_pronouns_list.append(personal_pronouns)\n",
        "            avg_word_lengths.append(avg_word_length)\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: File not found: {file_path}\")\n",
        "        except PermissionError:\n",
        "            print(f\"Error: Permission denied: {file_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Add new columns to the input_data DataFrame\n",
        "input_data['POSITIVE SCORE'] = positive_scores\n",
        "input_data['NEGATIVE SCORE'] = [-score for score in positive_scores]  # Adding negative scores\n",
        "input_data['POLARITY SCORE'] = polarity_scores\n",
        "input_data['SUBJECTIVITY SCORE'] = subjectivity_scores\n",
        "input_data['AVG SENTENCE LENGTH'] = avg_sentence_lengths\n",
        "input_data['PERCENTAGE OF COMPLEX WORDS'] = percentage_complex_words_list\n",
        "input_data['FOG INDEX'] = fog_indices\n",
        "input_data['AVG NUMBER OF WORDS PER SENTENCE'] = avg_words_per_sentence_list\n",
        "input_data['COMPLEX WORD COUNT'] = complex_word_counts\n",
        "input_data['WORD COUNT'] = word_counts\n",
        "input_data['SYLLABLE PER WORD'] = syllables_per_words\n",
        "input_data['PERSONAL PRONOUNS'] = personal_pronouns_list\n",
        "input_data['AVG WORD LENGTH'] = avg_word_lengths\n",
        "\n",
        "# Save the updated input_data to a new Excel file\n",
        "input_data.to_excel(\"Output.xlsx\", index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
